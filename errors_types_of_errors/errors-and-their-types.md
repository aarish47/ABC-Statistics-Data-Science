# **Errors and their types in ABC Statistics**

## **Written by:** Aarish Asif Khan

## **Date:** 19 January 2024 

> # **What are errors??**

In a general sense, an error is a mistake, deviation, or inaccuracy that occurs when something doesn't go as planned or expected.

Errors can occur in various fields and contexts, and their nature and impact depend on the specific area in which they occur. Here are a few broad definitions:

> **General Definition:**

**Error:** A deviation from accuracy, correctness, or the expected outcome. It signifies the presence of mistakes or unintended discrepancies.

> **In Programming:**

**Error:** In programming, an error refers to a mistake in the source code or its execution that prevents the program from running as intended. Errors can be syntax errors, runtime errors, or logical errors.

> **In Statistics:**

**Error:** In statistics, errors are differences between observed or calculated values and true or expected values. These can include sampling errors, measurement errors, and others that affect the accuracy of statistical analyses.

> **In Measurement:**

**Error:** In measurement, it represents the difference between the measured value and the true value. This difference can be due to instrument limitations, human errors, or other factors influencing the measurement process.

> **In Experimental Design:**

**Error:** Refers to variability or discrepancies in data that are not attributed to the variables under study. It includes random errors and systematic errors that can affect the validity of experimental results.

> **In Communication:**

**Error:** In communication, an error can be a misunderstanding or misinterpretation of information, leading to confusion or incorrect transmission of messages.

> **In Mathematics:**

**Error:** In mathematics, it typically denotes the difference between a computed or measured value and the true or expected value. It is often used in the context of approximations and estimations.

> # **The two main types of Errors in ABC Statistics**

1. Random error
2. Systematic error

> # **What are random and systematic errors??**

In the context of measurements and experimental design, both random errors and systematic errors contribute to the overall uncertainty or inaccuracy of measurements. Let's explore each type:

> **Random Errors:**

**Definition:** Random errors are unpredictable variations in measurements that occur randomly and are not consistent in magnitude or direction.

**Characteristics:**
- Arise from various uncontrollable and unpredictable factors.
- Tend to fluctuate and balance out over repeated measurements.
- Can be caused by instrument limitations, environmental conditions, or other unpredictable factors.

**Example:** If you weigh an object on a scale multiple times and get slightly different readings each time due to small fluctuations in the scale or other uncontrollable factors, those variations are random errors.

> **Systematic Errors**:

**Definition**: Systematic errors are consistent and predictable inaccuracies or biases in measurements that occur consistently in the same direction or manner.

**Characteristics:**

- Arise from flaws or biases in the measurement system or experimental setup.
- Result in a consistent shift or deviation from the true value.
- Do not tend to cancel out over repeated measurements.

**Example:** If a scale is consistently miscalibrated and consistently reads weights as 2 pounds too high, every measurement taken on that scale will have a systematic error of +2 pounds.

> # **Type 1 and Type 2 errors**

Type I and Type II errors are concepts used in hypothesis testing, a statistical method for making inferences about a population based on a sample of data. 

These errors relate to the decisions made regarding the acceptance or rejection of a null hypothesis. Let's explore each type:

> **Type I Error (False Positive):**

**Definition:** A Type I error occurs when the null hypothesis is incorrectly rejected when it is actually true.

**Symbol:** Often denoted by the Greek letter alpha (α).

**Characteristics:**

- It represents a situation where the test incorrectly concludes that there is a significant effect or difference when, in reality, there is none.
- The probability of committing a Type I error is equal to the chosen significance level (α) for the test.

**Example:** Concluding that a new drug is effective (rejecting the null hypothesis) when, in fact, it has no effect.

**Type II Error (False Negative):**

**Definition:** A Type II error occurs when the null hypothesis is not rejected when it is actually false.

**Symbol:** Often denoted by the Greek letter beta (β).

**Characteristics:**
- It represents a situation where the test fails to detect a significant effect or difference that truly exists.
- The probability of committing a Type II error is influenced by factors such as sample size, effect size, and the chosen significance level.

**Example:** Failing to reject the null hypothesis and concluding that a new drug has no effect when, in fact, it does.


